{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "     |████████████████████████████████| 249 kB 7.4 MB/s            \n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from scipy.signal import correlate2d, find_peaks\n",
    "import cv2\n",
    "from openpyxl import load_workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exif_data(image_path):\n",
    "    \"\"\"\n",
    "    Function to extract specific EXIF metadata - GPS coordinates, \n",
    "    camera model, and focal length from an image file. \n",
    "    --------------------------------------------------------------\n",
    "    Parameters:\n",
    "    image_path: A string representing the file path of the image from which the EXIF data is to be extracted.\n",
    "    --------------------------------------------------------------\n",
    "    Returns:\n",
    "    A tuple of lists containing the EXIF tags and their corresponding values.\n",
    "    \"\"\"\n",
    "    desired_tags = ['GPSLatitudeRef', 'GPSLatitude', 'GPSLongitudeRef', 'GPSLongitude', 'GPSAltitude', 'Model', 'FocalLength', \"DateTime\"]\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    exif_data = image._getexif()\n",
    "    exif_dict = {}\n",
    "\n",
    "    if exif_data is not None:\n",
    "        for key, value in exif_data.items():\n",
    "            if key in TAGS:\n",
    "                tag = TAGS[key]\n",
    "\n",
    "                if tag == 'GPSInfo':\n",
    "                    gps_data = {}\n",
    "                    for t in value:\n",
    "                        sub_tag = GPSTAGS.get(t, t)\n",
    "                        if sub_tag in desired_tags:\n",
    "                            gps_data[sub_tag] = value[t]\n",
    "                    exif_dict.update(gps_data)\n",
    "                elif tag in desired_tags:\n",
    "                    exif_dict[tag] = value\n",
    "\n",
    "    return exif_dict\n",
    "\n",
    "def get_geo_coord(lat, ref_lat, lon, ref_lon):\n",
    "    \"\"\"\n",
    "    Function to convert EXIF GPS coordinates to decimal format.\n",
    "    --------------------------------------------------------------\n",
    "    Parameters:\n",
    "    lat: A list of tuples containing the GPS latitude coordinates in degrees, minutes, and seconds.\n",
    "    ref_lat: A string representing the reference direction(N, S) of the GPS latitude coordinates.\n",
    "    lon: A list of tuples containing the GPS longitude coordinates in degrees, minutes, and seconds.\n",
    "    ref_lon: A string representing the reference direction(E, W) of the GPS longitude coordinates.\n",
    "    --------------------------------------------------------------\n",
    "    Returns:\n",
    "    A tuple of floats representing the GPS coordinates in decimal format.\n",
    "    \"\"\"\n",
    "    deg, minutes, seconds = lat\n",
    "    decimal_deg_lat = deg + (minutes / 60.0) + (seconds / 3600.0)\n",
    "\n",
    "    # Adjusting for the reference direction\n",
    "    if ref_lat == 'S':\n",
    "        decimal_deg_lat *= -1\n",
    "\n",
    "    deg, minutes, seconds = lon\n",
    "    decimal_deg_lon = deg + (minutes / 60.0) + (seconds / 3600.0)\n",
    "\n",
    "    # Adjusting for the reference direction\n",
    "    if ref_lon == 'W':\n",
    "        decimal_deg_lon *= -1\n",
    "\n",
    "    return decimal_deg_lat, decimal_deg_lon\n",
    "\n",
    "\n",
    "def calculate_fov_and_scene_dimensions(focal_length, sensor_width, sensor_height, distance):\n",
    "    # Calculate Field of View (FoV) in degrees\n",
    "    fov_horizontal = 2 * math.degrees(math.atan(sensor_width / (2 * focal_length)))\n",
    "    fov_vertical = 2 * math.degrees(math.atan(sensor_height / (2 * focal_length)))\n",
    "\n",
    "    # Calculate scene dimensions in kilometers\n",
    "    scene_width = 2 * distance * math.tan(math.radians(fov_horizontal) / 2)\n",
    "    scene_height = 2 * distance * math.tan(math.radians(fov_vertical) / 2)\n",
    "\n",
    "    return fov_horizontal, fov_vertical, scene_width, scene_height\n",
    "\n",
    "def mercator_projection(lat):\n",
    "    \"\"\"\n",
    "    Author: ChatGPT-4\n",
    "    This function converts latitude to Mercator projection.\n",
    "    --------------------------------------------------------------\n",
    "    Parameters:\n",
    "    lat (float): Latitude in degrees.\n",
    "    --------------------------------------------------------------\n",
    "    Returns:\n",
    "    float: Latitude in Mercator projection.\n",
    "    \"\"\"\n",
    "    return math.log(math.tan(math.radians(lat) / 2 + math.pi / 4))\n",
    "\n",
    "def calculate_mapbox_bounding_box(lat_center, lon_center, zoom, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Author: ChatGPT-4\n",
    "    This function calculates the bounding box of a Mapbox map.\n",
    "    --------------------------------------------------------------\n",
    "    Parameters:\n",
    "    lat_center (float): Latitude of the center of the map.\n",
    "    lon_center (float): Longitude of the center of the map.\n",
    "    zoom (int): Zoom level of the map.\n",
    "    image_width (int): Width of the image.\n",
    "    image_height (int): Height of the image.\n",
    "    --------------------------------------------------------------\n",
    "    Returns:\n",
    "    tuple: A tuple containing the coordinates of the top-left, top-right, bottom-right, and bottom-left corners of the image.\n",
    "    \"\"\"\n",
    "    # Tile size (in pixels) used by Mapbox\n",
    "    tile_size = 512\n",
    "\n",
    "    # Number of tiles at the given zoom level\n",
    "    num_tiles = 2 ** zoom\n",
    "\n",
    "    # Scale factor at this zoom level\n",
    "    scale = num_tiles * tile_size\n",
    "\n",
    "    # Latitude in Mercator projection\n",
    "    mercator_lat = mercator_projection(lat_center)\n",
    "\n",
    "    # Convert center longitude and latitude to pixel values\n",
    "    pixel_x_center = (lon_center + 180) / 360 * scale\n",
    "    pixel_y_center = (1 - mercator_lat / math.pi) / 2 * scale\n",
    "\n",
    "    # Calculate pixel coordinates of the corners\n",
    "    pixel_x_left = pixel_x_center - image_width / 2\n",
    "    pixel_x_right = pixel_x_center + image_width / 2\n",
    "    pixel_y_top = pixel_y_center - image_height / 2\n",
    "    pixel_y_bottom = pixel_y_center + image_height / 2\n",
    "\n",
    "    # Convert pixel coordinates back to lat/lon\n",
    "    def pixels_to_latlon(px, py):\n",
    "        lon = px / scale * 360 - 180\n",
    "        lat = math.degrees(2 * math.atan(math.exp((1 - 2 * py / scale) * math.pi)) - math.pi / 2)\n",
    "        return lat, lon\n",
    "\n",
    "    top_left = pixels_to_latlon(pixel_x_left, pixel_y_top)\n",
    "    top_right = pixels_to_latlon(pixel_x_right, pixel_y_top)\n",
    "    bottom_right = pixels_to_latlon(pixel_x_right, pixel_y_bottom)\n",
    "    bottom_left = pixels_to_latlon(pixel_x_left, pixel_y_bottom)\n",
    "\n",
    "    return top_left, top_right, bottom_right, bottom_left\n",
    "\n",
    "\n",
    "def save_aoi_image(image, file_name, aoi_image_folder):\n",
    "    if image is not None:\n",
    "        # Remove the file extension and append '_aoi.jpg'\n",
    "        aoi_image_base_name = os.path.splitext(file_name)[0] + \"_aoi.jpg\"\n",
    "        \n",
    "        # Ensure the folder exists\n",
    "        os.makedirs(aoi_image_folder, exist_ok=True)\n",
    "        \n",
    "        # Combine the folder path with the modified file name\n",
    "        aoi_image_file_path = os.path.join(aoi_image_folder, aoi_image_base_name)\n",
    "\n",
    "        # Save the image in JPG format\n",
    "        image.save(aoi_image_file_path, \"JPEG\")\n",
    "        print(f\"AOI image saved at {aoi_image_file_path}\")\n",
    "    else:\n",
    "        print(\"No image to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google maps view extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# GoogleMapDownloader.py \n",
    "# Created by Adrien de Jauréguiberry\n",
    "#\n",
    "# A script which when given a longitude, latitude, length\n",
    "# returns a high resolution google map\n",
    "\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "import os\n",
    "from math import *\n",
    "\n",
    "class GoogleMapDownloader:\n",
    "    \"\"\"\n",
    "        A class which generates high resolution google maps images given\n",
    "        a gmap API key and location parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, API_key, lat, lng, lgth, img_size=1000):\n",
    "        \"\"\"\n",
    "            GoogleMapDownloader Constructor\n",
    "            Args:\n",
    "                API_key:  The GoogleMap API key to load images\n",
    "                lat:      The latitude of the location required\n",
    "                lng:      The longitude of the location required\n",
    "                lgth:     Length of the map in m. The map will be a square.\n",
    "                          warning: too big length will result in distorded map due to mercator projection.\n",
    "                img_size: The resolution of the output image as img_size X img_size\n",
    "                          default to 1000\n",
    "        \"\"\"\n",
    "        lat_rad = (pi/180)*lat\n",
    "        self._img_size = img_size\n",
    "        self._lat = lat\n",
    "        self._lng = lng\n",
    "        self._zoom = floor(log2(156543.03 * img_size / lgth))\n",
    "        self._resolution = 156543.03 / (2 ** self._zoom) #(m/px)\n",
    "        self._nb_tiles = ceil(img_size/500)\n",
    "        self._tile_lgth = lgth/self._nb_tiles\n",
    "        self._tile_size = int(self._tile_lgth/self._resolution)\n",
    "        self._API_key = API_key\n",
    "\n",
    "    def getMercatorFromGPS(self,lng,lat):\n",
    "    \tx = 6371000 * lng\n",
    "    \ty = 6371000 * log(tan(pi/4 + lat/2))\n",
    "    \treturn (x,y)\n",
    "\n",
    "    def getGPSFromMercator(self,x,y):\n",
    "    \tlng = x/6371000\n",
    "    \tlat = 2*atan(exp(y/6371000)) - pi/2\n",
    "    \treturn (lng,lat)\n",
    "    \n",
    "    def get_zoom_level(self):\n",
    "        return self._zoom\n",
    "\n",
    "    def generateImage(self):\n",
    "        \"\"\"\n",
    "            Generates an image by stitching a number of google map tiles together.\n",
    "            \n",
    "            Returns:\n",
    "                A high-resolution Goole Map image.\n",
    "        \"\"\"\n",
    "\n",
    "        lat_rad = (pi/180)*abs(self._lat)\n",
    "        lng_rad = (pi/180)*abs(self._lng)\n",
    "        xy_loc  = self.getMercatorFromGPS(lng_rad,lat_rad)\n",
    "\n",
    "        xy_with_step  = [xy_loc[0]+self._tile_lgth , xy_loc[1]+self._tile_lgth]\n",
    "        gps_with_step = self.getGPSFromMercator(xy_with_step[0], xy_with_step[1])\n",
    "\n",
    "        lat_step = (180/pi)*(gps_with_step[1] - lat_rad)\n",
    "        lon_step = (180/pi)*(gps_with_step[0] - lng_rad)\n",
    "\n",
    "        border = 20        \n",
    "\n",
    "        # Determine the size of the image\n",
    "        width, height = self._tile_size * self._nb_tiles, self._tile_size * self._nb_tiles\n",
    "\n",
    "        #Create a new image of the size require\n",
    "        map_img = Image.new('RGB', (width,height))\n",
    "\n",
    "\n",
    "        nb_tiles_max = self._nb_tiles**2\n",
    "        counter = 1\n",
    "        for x in range(0, self._nb_tiles):\n",
    "            for y in range(0, self._nb_tiles) :\n",
    "\n",
    "                la = self._lat - y*lat_step + lat_step*(self._nb_tiles-1)/2\n",
    "                lo = self._lng + x*lon_step - lon_step*(self._nb_tiles-1)/2\n",
    "\n",
    "                url = 'https://maps.googleapis.com/maps/api/staticmap?'\n",
    "                url += 'center='+str(la)+','+str(lo)\n",
    "                url += '&zoom='+str(self._zoom)\n",
    "                url += '&size='+str(self._tile_size+2*border)+'x'+str(self._tile_size+2*border)\n",
    "                url += '&maptype=satellite'\n",
    "                if self._API_key:url += '&key='+self._API_key\n",
    "                print('getting tile '+str(counter)+\"/\"+str(nb_tiles_max))\n",
    "                counter+=1\n",
    "\n",
    "                current_tile = str(x)+'-'+str(y)\n",
    "                request.urlretrieve(url, current_tile)\n",
    "            \n",
    "                im = Image.open(current_tile)\n",
    "                map_img.paste(im.crop((border,border,self._tile_size+border,self._tile_size+border)), (x*self._tile_size, y*self._tile_size))\n",
    "              \n",
    "                os.remove(current_tile)\n",
    "\n",
    "        print(\"Resizing map\")\n",
    "        return map_img.resize((self._img_size,self._img_size))\n",
    "\n",
    "import os\n",
    "\n",
    "def download_map_image(api_key, lat, lng, map_length, image_size):\n",
    "    gmd = GoogleMapDownloader(api_key, lat, lng, map_length, image_size)\n",
    "    try:\n",
    "        # Generate the high-resolution map image\n",
    "        return gmd.generateImage()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not generate the image - {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get the zoom level\n",
    "def get_map_zoom(api_key, lat, lng, map_length, image_size):\n",
    "    gmd = GoogleMapDownloader(api_key, lat, lng, map_length, image_size)\n",
    "    return gmd.get_zoom_level()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Function to get image dimensions\n",
    "def get_image_dimensions(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found or the path is incorrect\")\n",
    "    return image.shape[1], image.shape[0]  # Width, Height\n",
    "\n",
    "def kernal_window_finder(image_width_px, image_height_px, covered_area_width_km, covered_area_height_km, target_area_width_km, target_area_height_km):\n",
    "    \"\"\"\n",
    "    Calculate the pixel dimensions for a given kilometer area in an image, rounded to the nearest whole number.\n",
    "\n",
    "    Parameters:\n",
    "    image_width_px (int): Width of the image in pixels.\n",
    "    image_height_px (int): Height of the image in pixels.\n",
    "    covered_area_width_km (float): Width of the area covered by the image in kilometers.\n",
    "    covered_area_height_km (float): Height of the area covered by the image in kilometers.\n",
    "    target_area_width_km (float): Width of the target area in kilometers.\n",
    "    target_area_height_km (float): Height of the target area in kilometers.\n",
    "\n",
    "    Returns:\n",
    "    (int, int): Width and height of the target area in pixels, rounded to the nearest whole number.\n",
    "    \"\"\"\n",
    "\n",
    "    # The number of pixels per km in both dimensions\n",
    "    pixels_per_km_width = image_width_px / covered_area_width_km\n",
    "    pixels_per_km_height = image_height_px / covered_area_height_km\n",
    "\n",
    "    # Calculating the pixel dimensions for the target area\n",
    "    target_area_width_px = round(target_area_width_km * pixels_per_km_width)\n",
    "    target_area_height_px = round(target_area_height_km * pixels_per_km_height)\n",
    "\n",
    "    return target_area_width_px, target_area_height_px\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def subsample_images(image_path, output_folder, window_width, window_height, stride_x, stride_y):\n",
    "    \"\"\"\n",
    "    Generate subsampled images from a reference image using a sliding window and print the total number of images generated.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): Path to the reference image.\n",
    "    output_folder (str): Path to the folder where subsampled images will be saved.\n",
    "    window_width (int): Width of the sliding window in pixels.\n",
    "    window_height (int): Height of the sliding window in pixels.\n",
    "    stride_x (int): Horizontal stride of the sliding window in pixels.\n",
    "    stride_y (int): Vertical stride of the sliding window in pixels.\n",
    "    \"\"\"\n",
    "    # Load the reference image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Count the number of subsamples generated\n",
    "    num_subsamples = 0\n",
    "\n",
    "    print(\"Generating subsampled images...\")\n",
    "\n",
    "    # Iterate over the image using the sliding window\n",
    "    for y in range(0, image.height - window_height + 1, stride_y):\n",
    "        for x in range(0, image.width - window_width + 1, stride_x):\n",
    "            # Extract the sub-image\n",
    "            sub_image = image.crop((x, y, x + window_width, y + window_height))\n",
    "\n",
    "            # Save the sub-image\n",
    "            sub_image_path = os.path.join(output_folder, f\"subsample_{x}_{y}.jpg\")\n",
    "            sub_image.save(sub_image_path)\n",
    "            num_subsamples += 1\n",
    "            # print(f\"Subsample saved: {sub_image_path}\")\n",
    "\n",
    "    # Print the total number of subsamples generated\n",
    "    print(f\"Total number of subsampled images generated: {num_subsamples}\")\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "\n",
    "def resize_image(image, max_size=800):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = max_size / max(h, w)\n",
    "\n",
    "    if scale < 1:\n",
    "        image = cv2.resize(image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)\n",
    "    return image\n",
    "\n",
    "def sift_detect_and_compute(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return None, None\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def match_features(descriptors1, descriptors2):\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return []\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    # Ensure there are at least 2 matches to unpack\n",
    "    if len(matches) < 2:\n",
    "        return []\n",
    "    return matches\n",
    "\n",
    "\n",
    "def filter_good_matches(matches):\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "def find_homography(keypoints1, keypoints2, good_matches):\n",
    "    if not good_matches:\n",
    "        return None, None\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return M, mask\n",
    "\n",
    "def visualize_matches(image1, keypoints1, image2, keypoints2, matches, mask):\n",
    "    if mask is None:\n",
    "        print(\"Homography could not be computed.\")\n",
    "        return\n",
    "    draw_params = dict(matchColor=(0, 255, 0),\n",
    "                       singlePointColor=None,\n",
    "                       matchesMask=mask.ravel().tolist(),\n",
    "                       flags=2)\n",
    "    img_matches = cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches, None, **draw_params)\n",
    "    img_matches = cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(img_matches)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def match_query_to_scene(query_image_path, scene_image_path):\n",
    "    query_image = cv2.imread(query_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if query_image is None:\n",
    "        raise ValueError(f\"Could not load the query image from path: {query_image_path}\")\n",
    "    query_image = resize_image(query_image)\n",
    "\n",
    "    scene_image = cv2.imread(scene_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if scene_image is None:\n",
    "        raise ValueError(f\"Could not load the scene image from path: {scene_image_path}\")\n",
    "    scene_image = resize_image(scene_image)\n",
    "\n",
    "    keypoints_query, descriptors_query = sift_detect_and_compute(query_image)\n",
    "    keypoints_scene, descriptors_scene = sift_detect_and_compute(scene_image)\n",
    "\n",
    "    matches = match_features(descriptors_query, descriptors_scene)\n",
    "    good_matches = filter_good_matches(matches)\n",
    "\n",
    "    if len(good_matches) > 10:\n",
    "        M, mask = find_homography(keypoints_query, keypoints_scene, good_matches)\n",
    "        if M is not None:\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "            matching_percentage = (sum(matchesMask) / len(good_matches)) * 100\n",
    "            print(f\"Match found with {scene_image_path}: {matching_percentage:.2f}%\")\n",
    "            return scene_image_path, matching_percentage, (keypoints_scene, good_matches, matchesMask)\n",
    "    else:\n",
    "        pass\n",
    "#         print(f\"Not enough good matches found for {scene_image_path}\")\n",
    "\n",
    "    return scene_image_path, 0, (None, None, None)  # Return zero if homography not found or not enough good matches\n",
    "\n",
    "# def calculate_center_pixel(keypoints_scene, good_matches, matchesMask):\n",
    "#     matched_pts = [keypoints_scene[m.trainIdx].pt for m, mask in zip(good_matches, matchesMask) if mask]\n",
    "#     if not matched_pts:\n",
    "#         return (0, 0)\n",
    "#     x, y = zip(*matched_pts)\n",
    "#     center_x, center_y = sum(x) / len(x), sum(y) / len(y)\n",
    "#     return int(center_x), int(center_y)\n",
    "\n",
    "# def pixel_to_geo(pixel_x, pixel_y, top_left_geo, bottom_right_geo, image_width_px, image_height_px):\n",
    "#     lat_range = bottom_right_geo[0] - top_left_geo[0]\n",
    "#     lon_range = bottom_right_geo[1] - top_left_geo[1]\n",
    "\n",
    "#     geo_x = top_left_geo[1] + (pixel_x / image_width_px) * lon_range\n",
    "#     geo_y = top_left_geo[0] + (pixel_y / image_height_px) * lat_range\n",
    "\n",
    "#     return geo_x, geo_y\n",
    "\n",
    "def calculate_pixel_to_geo(top_left_geo, bottom_right_geo, image_width_px, image_height_px, pixel_x, pixel_y):\n",
    "    # New function to calculate geographic coordinates from pixel coordinates\n",
    "    lat_range = bottom_right_geo[0] - top_left_geo[0]\n",
    "    lon_range = bottom_right_geo[1] - top_left_geo[1]\n",
    "\n",
    "    lat_per_pixel = lat_range / image_height_px\n",
    "    lon_per_pixel = lon_range / image_width_px\n",
    "\n",
    "    geo_x = top_left_geo[1] + pixel_x * lon_per_pixel\n",
    "    geo_y = top_left_geo[0] + pixel_y * lat_per_pixel\n",
    "\n",
    "    return geo_y, geo_x\n",
    "\n",
    "def compare_images_with_query(query_image_path, directory_path, num_matches=1):\n",
    "    best_match_paths = []\n",
    "\n",
    "    matches_info = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for image_path in glob.glob(directory_path + '/*.jpg'):\n",
    "        try:\n",
    "            image_path, matching_percentage, match_data = match_query_to_scene(query_image_path, image_path)\n",
    "            matches_info.append((image_path, matching_percentage, match_data))\n",
    "        except Exception as e:\n",
    "            print(f\"Error comparing images: {e}\")\n",
    "\n",
    "    matches_info.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get top N matches based on num_matches\n",
    "    for i in range(min(num_matches, len(matches_info))):\n",
    "        best_match_info = matches_info[i]\n",
    "        best_match_path, best_match_percentage, _ = best_match_info\n",
    "        print(f\"Visualizing match with {best_match_path}: {best_match_percentage:.2f}%\")\n",
    "        match_query_to_scene(query_image_path, best_match_path)\n",
    "        best_match_paths.append(best_match_path)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Total time taken: {total_time:.2f} seconds\")\n",
    "\n",
    "    return best_match_paths\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_subsample_offsets(best_match_path):\n",
    "    # Extract the file name without the directory\n",
    "    file_name = os.path.basename(best_match_path)\n",
    "    # Split the file name into parts\n",
    "    parts = file_name.split('_')\n",
    "    # The offsets are the last two parts before the file extension, convert them to integers\n",
    "    offset_x = int(parts[-2])\n",
    "    offset_y = int(parts[-1].split('.')[0])  # Remove the file extension before converting\n",
    "    return offset_x, offset_y\n",
    "\n",
    "def get_center_pixel_of_subsample(subsample_path):\n",
    "    subsample_image = cv2.imread(subsample_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if subsample_image is None:\n",
    "        raise ValueError(f\"Could not load the subsample image from path: {subsample_path}\")\n",
    "    h, w = subsample_image.shape[:2]\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "    return center_x, center_y\n",
    "\n",
    "def calculate_subsample_geo_center(subsample_path, large_area_image_path, top_left_geo, bottom_right_geo, subsample_offset_x, subsample_offset_y):\n",
    "    # Get the dimensions of the large area image\n",
    "    large_image_width_px, large_image_height_px = get_image_dimensions(large_area_image_path)\n",
    "\n",
    "    # Calculate the center pixel of the subsample\n",
    "    center_pixel_x, center_pixel_y = get_center_pixel_of_subsample(subsample_path)\n",
    "\n",
    "    # Calculate the absolute pixel coordinates of the center in the large area image\n",
    "    absolute_center_x = subsample_offset_x + center_pixel_x\n",
    "    absolute_center_y = subsample_offset_y + center_pixel_y\n",
    "\n",
    "    # Convert these absolute pixel coordinates to geographic coordinates\n",
    "    geo_center = calculate_pixel_to_geo(top_left_geo, bottom_right_geo, large_image_width_px, large_image_height_px, absolute_center_x, absolute_center_y)\n",
    "    \n",
    "    return geo_center\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_iss_image(query_image_name, api_key):\n",
    "    # Loading query image and extracting metadata for Formentera\n",
    "\n",
    "    query_image_folder = \"../data/images/\"\n",
    "    query_image_name = query_image_name   \n",
    "    query_image_path = query_image_folder + query_image_name    \n",
    "\n",
    "    exif_data = get_exif_data(query_image_path)\n",
    "\n",
    "    print(f\"Extracted Metadata:\\n {exif_data}\")\n",
    "\n",
    "\n",
    "    gps_latitude = exif_data.get('GPSLatitude', None)\n",
    "    gps_latitude_ref = exif_data.get('GPSLatitudeRef', None)\n",
    "    gps_longitude = exif_data.get('GPSLongitude', None)\n",
    "    gps_longitude_ref = exif_data.get('GPSLongitudeRef', None)\n",
    "    gps_altitude = exif_data.get('GPSAltitude', None)\n",
    "    focal_length = exif_data.get('FocalLength', None)\n",
    "\n",
    "    # Check if all GPS data is available\n",
    "    if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n",
    "        lat, long = get_geo_coord(gps_latitude, gps_latitude_ref, gps_longitude, gps_longitude_ref)\n",
    "        print(f\"ISS coordinates: {lat}, {long}\")\n",
    "    else:\n",
    "        print(\"GPS data is incomplete or not available in the image.\")\n",
    "\n",
    "\n",
    "    # These correspond to a Nikon D5\n",
    "    sensor_width = 36  # in millimeters (for a full-frame sensor like Nikon D5)\n",
    "    sensor_height = 24  # in millimeters\n",
    "\n",
    "    # Distance of the ISS camera to earth\n",
    "    distance = gps_altitude /1000  # in kilometers\n",
    "\n",
    "    # scene dimensions in kilometers. It will help in finding the kernal size of sliding window.\n",
    "    fov_horizontal, fov_vertical, query_image_width_km, query_image_height_km = calculate_fov_and_scene_dimensions(focal_length, sensor_width, sensor_height, distance)\n",
    "    print(f\"scene width: {query_image_width_km} km and scene height: {query_image_height_km} km\")\n",
    "\n",
    "\n",
    "    # Downloading area of interest image and getting bounding box coordinates\n",
    "    api_key = api_key\n",
    "    map_length = 1200000  # in meters\n",
    "    image_size = 30000  # width and height in pixels\n",
    "    aoi_image_folder = \"../data/aoi_images/\"\n",
    "\n",
    "    # AOI image file path construction\n",
    "    aoi_image_base_name = os.path.splitext(query_image_name)[0] + \"_aoi.jpg\"\n",
    "    aoi_image_file_path = os.path.join(aoi_image_folder, aoi_image_base_name)\n",
    "\n",
    "    # Instantiate GoogleMapDownloader object\n",
    "    gmd = GoogleMapDownloader(api_key, lat, long, map_length, image_size)\n",
    "\n",
    "    # Check if AOI image already exists\n",
    "    if not os.path.exists(aoi_image_file_path):\n",
    "        # Download the map image if it doesn't exist\n",
    "        image = gmd.generateImage()\n",
    "\n",
    "        # Save the image if it is not None\n",
    "        if image is not None:\n",
    "            # Ensure the folder exists\n",
    "            os.makedirs(aoi_image_folder, exist_ok=True)\n",
    "\n",
    "            # Save the image in JPG format\n",
    "            image.save(aoi_image_file_path, \"JPEG\")\n",
    "            print(f\"AOI image saved at {aoi_image_file_path}\")\n",
    "        else:\n",
    "            print(\"No image to save.\")\n",
    "    else:\n",
    "        print(f\"AOI image already exists at {aoi_image_file_path}\")\n",
    "\n",
    "    # Retrieve the zoom level in both cases (new download or existing file)\n",
    "    zoom = gmd.get_zoom_level()\n",
    "    print(f\"Zoom level: {zoom}\")\n",
    "\n",
    "\n",
    "    # # manual check inputs:\n",
    "    # aoi_image_file_path =\"../data/aoi_images/iss050e070478_aoi.jpg\"\n",
    "    # zoom =11\n",
    "\n",
    "\n",
    "    # Calculate the bounding box coordinates\n",
    "    top_left_aoi, top_right_aoi, bottom_right_aoi, bottom_left_aoi = calculate_mapbox_bounding_box(lat, long, zoom, image_size, image_size)\n",
    "    print(\"top_left_aoi:\",top_left_aoi)\n",
    "    print(\"top_right_aoi:\",top_right_aoi)\n",
    "    print(\"bottom_right_aoi:\",bottom_right_aoi)\n",
    "    print(\"bottom_left_aoi:\",bottom_left_aoi)\n",
    "\n",
    "\n",
    "    # Using SIFT matcher\n",
    "    distance_km = map_length/2000  # convert meters in kilometers\n",
    "    rounded_width_km = math.ceil(query_image_width_km)\n",
    "    rounded_height_km = math.ceil(query_image_height_km)\n",
    "    kernal_width_px, kernal_height_px = kernal_window_finder(image_size, image_size, distance_km, distance_km, rounded_width_km, rounded_height_km)\n",
    "    print(\"Kernal Width in pixels:\", kernal_width_px, \", Kernal Height in pixels:\", kernal_height_px)\n",
    "\n",
    "    window_width = math.ceil(kernal_width_px*1.5)\n",
    "    window_height = math.ceil(kernal_height_px*1.5)\n",
    "    stride_x = kernal_width_px  # You can adjust the stride as needed\n",
    "    stride_y = kernal_height_px  # You can adjust the stride as needed\n",
    "\n",
    "    # Extract the base name without extension\n",
    "    base_name = os.path.splitext(query_image_name)[0]\n",
    "    # Create output folder path\n",
    "    aoi_subsample_output_folder_base = \"../data/aoi_subsampled_images/\"\n",
    "    aoi_subsample_output_folder_path = os.path.join(aoi_subsample_output_folder_base, \"subsampled_\" + base_name)\n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(aoi_subsample_output_folder_path):\n",
    "        os.makedirs(aoi_subsample_output_folder_path)\n",
    "\n",
    "\n",
    "    # Call the function \n",
    "    subsample_images(aoi_image_file_path, aoi_subsample_output_folder_path, window_width, window_height, stride_x, stride_y)\n",
    "\n",
    "    # Run the comparison and get top N matches\n",
    "    num_matches = 2  # Set the number of matches you want\n",
    "    best_match_paths = compare_images_with_query(query_image_path, aoi_subsample_output_folder_path, num_matches)\n",
    "    large_area_image_path = aoi_image_file_path \n",
    "    top_left_geo = top_left_aoi\n",
    "    bottom_right_geo = bottom_right_aoi\n",
    "\n",
    "    # Initialize a list to store geographic centers\n",
    "    geo_centers = []\n",
    "\n",
    "    # Process each match in the list\n",
    "    for match_path in best_match_paths:\n",
    "        # Extract the subsample offsets\n",
    "        subsample_offset_x, subsample_offset_y = extract_subsample_offsets(match_path)\n",
    "\n",
    "        # Calculate the geographic center coordinates\n",
    "        geo_center = calculate_subsample_geo_center(match_path, large_area_image_path, top_left_geo, bottom_right_geo, subsample_offset_x, subsample_offset_y)\n",
    "        print(f\"Geographic center of {match_path}: {geo_center}\")\n",
    "\n",
    "        # Append the geographic center to the list\n",
    "        geo_centers.append(geo_center)\n",
    "    \n",
    "    return geo_centers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing the result excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: iss050e070478\n",
      "Extracted Metadata:\n",
      " {'GPSLatitudeRef': 'N', 'GPSLatitude': (42.0, 10.3992, 0.0), 'GPSLongitudeRef': 'W', 'GPSLongitude': (74.0, 36.3344, 0.0), 'GPSAltitude': 404564.54545454547, 'Model': 'NIKON D4', 'DateTime': '2017:10:16 09:38:48', 'FocalLength': 1150.0}\n",
      "ISS coordinates: 42.17332, -74.60557333333334\n",
      "scene width: 12.664629249011858 km and scene height: 8.443086166007905 km\n",
      "AOI image already exists at ../data/aoi_images/iss050e070478_aoi.jpg\n",
      "Zoom level: 11\n",
      "top_left_aoi: (45.87446621205198, -79.75541464192709)\n",
      "top_right_aoi: (45.87446621205198, -69.45573202473959)\n",
      "bottom_right_aoi: (38.242217020514246, -69.45573202473959)\n",
      "bottom_left_aoi: (38.242217020514246, -79.75541464192709)\n",
      "Kernal Width in pixels: 650 , Kernal Height in pixels: 450\n",
      "Generating subsampled images...\n",
      "Total number of subsampled images generated: 2970\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_23400_4050.jpg: 54.55%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_14850.jpg: 35.71%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_17550_20700.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_8450_9900.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_20800_3600.jpg: 45.45%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_16250_7650.jpg: 36.36%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_13650_4950.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_19500_25650.jpg: 36.36%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_28600_9000.jpg: 83.33%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26650_3600.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_1950_1800.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24700_23850.jpg: 50.00%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_3250_8550.jpg: 54.55%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27950_22500.jpg: 42.86%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_15600_25200.jpg: 53.85%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_4550_0.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22100_24750.jpg: 50.00%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_20800_25650.jpg: 38.89%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_5200_9900.jpg: 58.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_18850_20700.jpg: 31.25%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26650_18450.jpg: 40.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_21450_25200.jpg: 37.50%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_14950_25650.jpg: 42.86%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_13500.jpg: 38.46%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26650_23400.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_18000.jpg: 33.33%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_19500_18450.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27950_14400.jpg: 52.38%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24700_17550.jpg: 52.94%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22100_18450.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_20150_20250.jpg: 53.85%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_12350_18000.jpg: 30.77%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_13000_26100.jpg: 50.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_9100_20250.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_15300.jpg: 35.71%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26000_18000.jpg: 35.71%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22100_18900.jpg: 41.67%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_28600_26550.jpg: 27.03%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_4500.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_20150_18450.jpg: 52.38%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_16250_20250.jpg: 52.63%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_13650_9900.jpg: 30.77%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_15600_9450.jpg: 45.45%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24700_26100.jpg: 28.57%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_20800_18450.jpg: 46.15%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22750_23850.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22100_23400.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_3900_900.jpg: 28.57%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_5850_8100.jpg: 41.18%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_11050_9450.jpg: 35.71%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_15600_24750.jpg: 54.55%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_15600_9900.jpg: 33.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22750_18450.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22750_24750.jpg: 41.67%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_2600_15300.jpg: 50.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_16900_29250.jpg: 30.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27950_16200.jpg: 31.58%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_8450_4050.jpg: 30.77%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_5850_450.jpg: 33.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_14300_10350.jpg: 41.67%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26650_15750.jpg: 60.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_7150_9900.jpg: 23.08%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24700_29250.jpg: 34.78%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27950_15750.jpg: 44.83%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_18850_27000.jpg: 33.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_23400_25200.jpg: 41.67%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_7800_8550.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22750_28800.jpg: 25.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_22100_19350.jpg: 54.55%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_18200_27900.jpg: 40.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24050_24750.jpg: 21.21%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_13000_27000.jpg: 54.55%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_13000_2700.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26650_22500.jpg: 54.55%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_5200_16650.jpg: 35.71%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_18200_3600.jpg: 35.71%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_28600_450.jpg: 33.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_16250_29250.jpg: 46.67%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_650_1350.jpg: 33.33%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_25350_29250.jpg: 73.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_3250_9900.jpg: 33.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27950_24300.jpg: 54.55%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27950_450.jpg: 38.46%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26000_13950.jpg: 26.67%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_9100_8100.jpg: 75.61%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_5850_900.jpg: 28.57%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24700_24300.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_23850.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_23400_24750.jpg: 29.41%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26650_17100.jpg: 42.86%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_14300_27000.jpg: 52.63%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24700_18000.jpg: 24.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26000_11700.jpg: 36.36%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27950_14850.jpg: 59.09%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_11700_18900.jpg: 45.45%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_24300.jpg: 62.90%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_8450_7650.jpg: 35.71%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_25350_13950.jpg: 56.67%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24050_22500.jpg: 40.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_19350.jpg: 10.87%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_17550_29250.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_5200_18000.jpg: 30.77%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_19500_1800.jpg: 63.64%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_3900_9900.jpg: 50.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_1300_13050.jpg: 44.44%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_9750_450.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24050_27450.jpg: 50.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_13000_26550.jpg: 26.53%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_25350_4500.jpg: 41.67%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26650_18000.jpg: 46.15%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_13650_29250.jpg: 40.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_18850_18900.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26000_12600.jpg: 35.71%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_15750.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24700_18450.jpg: 17.86%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_17550_28350.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_18200_4050.jpg: 42.86%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24050_25200.jpg: 33.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_9750_27900.jpg: 36.36%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_27300_17550.jpg: 36.36%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_9100_7650.jpg: 30.77%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24700_6750.jpg: 36.36%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_20800_5850.jpg: 36.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_25350_24300.jpg: 16.00%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_18200_28350.jpg: 41.67%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_23400_22500.jpg: 45.45%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_20150_25650.jpg: 30.77%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_26650_17550.jpg: 52.50%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_24050_9450.jpg: 45.45%\n",
      "Error comparing images: not enough values to unpack (expected 2, got 1)\n",
      "Visualizing match with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_28600_9000.jpg: 83.33%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_28600_9000.jpg: 83.33%\n",
      "Visualizing match with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_9100_8100.jpg: 75.61%\n",
      "Match found with ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_9100_8100.jpg: 75.61%\n",
      "Total time taken: 627.98 seconds\n",
      "Geographic center of ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_28600_9000.jpg: (43.49905585533905, -69.769185699056)\n",
      "Geographic center of ../data/aoi_subsampled_images/subsampled_iss050e070478/subsample_9100_8100.jpg: (43.72802333108518, -76.46397940022787)\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "import os\n",
    "\n",
    "# Replace with the path to your Excel file\n",
    "excel_file_path = '../results/results_SIFT_v1.xlsx'\n",
    "api_key = \"AIzaSyCxRtWpRRPYvcPlQl440mjoXWrvModq4XQ\"\n",
    "\n",
    "# Load the workbook and select the active worksheet\n",
    "wb = load_workbook(excel_file_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Iterate through the rows in the worksheet\n",
    "for row in ws.iter_rows(min_row=2, max_col=5):\n",
    "    image_cell, location_from_code_cell = row[0], row[4]\n",
    "\n",
    "    # If 'Location from code' is empty and 'Image' is not empty\n",
    "    if not location_from_code_cell.value and image_cell.value:\n",
    "        print(f\"Processing image: {image_cell.value}\")\n",
    "        query_image_name = image_cell.value + \".jpg\"\n",
    "\n",
    "        # Call your function to get the geographic centers\n",
    "        geo_centers = process_iss_image(query_image_name, api_key)\n",
    "\n",
    "        # Update the cell with the list of geo centers\n",
    "        location_from_code_cell.value = ', '.join(f\"({lat}, {lon})\" for lat, lon in geo_centers)\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(excel_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > SIFT_matcher_requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMA915f0wWqoCTWRdp9vlsI",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
