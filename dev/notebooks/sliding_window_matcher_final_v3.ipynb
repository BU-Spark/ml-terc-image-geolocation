{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install geopy\n",
    "# !pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "from io import BytesIO\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from scipy.signal import correlate2d, find_peaks\n",
    "import cv2\n",
    "from openpyxl import load_workbook\n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import getpass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exif_data(image_path):\n",
    "    \"\"\"\n",
    "    Function to extract specific EXIF metadata - GPS coordinates, \n",
    "    camera model, and focal length from an image file. \n",
    "    --------------------------------------------------------------\n",
    "    Parameters:\n",
    "    image_path: A string representing the file path of the image from which the EXIF data is to be extracted.\n",
    "    --------------------------------------------------------------\n",
    "    Returns:\n",
    "    A tuple of lists containing the EXIF tags and their corresponding values.\n",
    "    \"\"\"\n",
    "    desired_tags = ['GPSLatitudeRef', 'GPSLatitude', 'GPSLongitudeRef', 'GPSLongitude', 'GPSAltitude', 'Model', 'FocalLength', \"DateTime\"]\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    exif_data = image._getexif()\n",
    "    exif_dict = {}\n",
    "\n",
    "    if exif_data is not None:\n",
    "        for key, value in exif_data.items():\n",
    "            if key in TAGS:\n",
    "                tag = TAGS[key]\n",
    "\n",
    "                if tag == 'GPSInfo':\n",
    "                    gps_data = {}\n",
    "                    for t in value:\n",
    "                        sub_tag = GPSTAGS.get(t, t)\n",
    "                        if sub_tag in desired_tags:\n",
    "                            gps_data[sub_tag] = value[t]\n",
    "                    exif_dict.update(gps_data)\n",
    "                elif tag in desired_tags:\n",
    "                    exif_dict[tag] = value\n",
    "\n",
    "    return exif_dict\n",
    "\n",
    "def get_geo_coord(lat, ref_lat, lon, ref_lon):\n",
    "    \"\"\"\n",
    "    Function to convert EXIF GPS coordinates to decimal format.\n",
    "    --------------------------------------------------------------\n",
    "    Parameters:\n",
    "    lat: A list of tuples containing the GPS latitude coordinates in degrees, minutes, and seconds.\n",
    "    ref_lat: A string representing the reference direction(N, S) of the GPS latitude coordinates.\n",
    "    lon: A list of tuples containing the GPS longitude coordinates in degrees, minutes, and seconds.\n",
    "    ref_lon: A string representing the reference direction(E, W) of the GPS longitude coordinates.\n",
    "    --------------------------------------------------------------\n",
    "    Returns:\n",
    "    A tuple of floats representing the GPS coordinates in decimal format.\n",
    "    \"\"\"\n",
    "    deg, minutes, seconds = lat\n",
    "    decimal_deg_lat = deg + (minutes / 60.0) + (seconds / 3600.0)\n",
    "\n",
    "    # Adjusting for the reference direction\n",
    "    if ref_lat == 'S':\n",
    "        decimal_deg_lat *= -1\n",
    "\n",
    "    deg, minutes, seconds = lon\n",
    "    decimal_deg_lon = deg + (minutes / 60.0) + (seconds / 3600.0)\n",
    "\n",
    "    # Adjusting for the reference direction\n",
    "    if ref_lon == 'W':\n",
    "        decimal_deg_lon *= -1\n",
    "\n",
    "    return decimal_deg_lat, decimal_deg_lon\n",
    "\n",
    "\n",
    "def calculate_fov_and_scene_dimensions(focal_length, sensor_width, sensor_height, distance):\n",
    "    # Calculate Field of View (FoV) in degrees\n",
    "    fov_horizontal = 2 * math.degrees(math.atan(sensor_width / (2 * focal_length)))\n",
    "    fov_vertical = 2 * math.degrees(math.atan(sensor_height / (2 * focal_length)))\n",
    "\n",
    "    # Calculate scene dimensions in kilometers\n",
    "    scene_width = 2 * distance * math.tan(math.radians(fov_horizontal) / 2)\n",
    "    scene_height = 2 * distance * math.tan(math.radians(fov_vertical) / 2)\n",
    "\n",
    "    return fov_horizontal, fov_vertical, scene_width, scene_height\n",
    "\n",
    "def mercator_projection(lat):\n",
    "    \"\"\"\n",
    "    Author: ChatGPT-4\n",
    "    This function converts latitude to Mercator projection.\n",
    "    --------------------------------------------------------------\n",
    "    Parameters:\n",
    "    lat (float): Latitude in degrees.\n",
    "    --------------------------------------------------------------\n",
    "    Returns:\n",
    "    float: Latitude in Mercator projection.\n",
    "    \"\"\"\n",
    "    return math.log(math.tan(math.radians(lat) / 2 + math.pi / 4))\n",
    "\n",
    "def calculate_mapbox_bounding_box(lat_center, lon_center, zoom, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Author: ChatGPT-4\n",
    "    This function calculates the bounding box of a Mapbox map.\n",
    "    --------------------------------------------------------------\n",
    "    Parameters:\n",
    "    lat_center (float): Latitude of the center of the map.\n",
    "    lon_center (float): Longitude of the center of the map.\n",
    "    zoom (int): Zoom level of the map.\n",
    "    image_width (int): Width of the image.\n",
    "    image_height (int): Height of the image.\n",
    "    --------------------------------------------------------------\n",
    "    Returns:\n",
    "    tuple: A tuple containing the coordinates of the top-left, top-right, bottom-right, and bottom-left corners of the image.\n",
    "    \"\"\"\n",
    "    # Tile size (in pixels) used by Mapbox\n",
    "    tile_size = 512\n",
    "\n",
    "    # Number of tiles at the given zoom level\n",
    "    num_tiles = 2 ** zoom\n",
    "\n",
    "    # Scale factor at this zoom level\n",
    "    scale = num_tiles * tile_size\n",
    "\n",
    "    # Latitude in Mercator projection\n",
    "    mercator_lat = mercator_projection(lat_center)\n",
    "\n",
    "    # Convert center longitude and latitude to pixel values\n",
    "    pixel_x_center = (lon_center + 180) / 360 * scale\n",
    "    pixel_y_center = (1 - mercator_lat / math.pi) / 2 * scale\n",
    "\n",
    "    # Calculate pixel coordinates of the corners\n",
    "    pixel_x_left = pixel_x_center - image_width / 2\n",
    "    pixel_x_right = pixel_x_center + image_width / 2\n",
    "    pixel_y_top = pixel_y_center - image_height / 2\n",
    "    pixel_y_bottom = pixel_y_center + image_height / 2\n",
    "\n",
    "    # Convert pixel coordinates back to lat/lon\n",
    "    def pixels_to_latlon(px, py):\n",
    "        lon = px / scale * 360 - 180\n",
    "        lat = math.degrees(2 * math.atan(math.exp((1 - 2 * py / scale) * math.pi)) - math.pi / 2)\n",
    "        return lat, lon\n",
    "\n",
    "    top_left = pixels_to_latlon(pixel_x_left, pixel_y_top)\n",
    "    top_right = pixels_to_latlon(pixel_x_right, pixel_y_top)\n",
    "    bottom_right = pixels_to_latlon(pixel_x_right, pixel_y_bottom)\n",
    "    bottom_left = pixels_to_latlon(pixel_x_left, pixel_y_bottom)\n",
    "\n",
    "    return top_left, top_right, bottom_right, bottom_left\n",
    "\n",
    "\n",
    "def save_aoi_image(image, file_name, aoi_image_folder):\n",
    "    if image is not None:\n",
    "        # Remove the file extension and append '_aoi.jpg'\n",
    "        aoi_image_base_name = os.path.splitext(file_name)[0] + \"_aoi.jpg\"\n",
    "        \n",
    "        # Ensure the folder exists\n",
    "        os.makedirs(aoi_image_folder, exist_ok=True)\n",
    "        \n",
    "        # Combine the folder path with the modified file name\n",
    "        aoi_image_file_path = os.path.join(aoi_image_folder, aoi_image_base_name)\n",
    "\n",
    "        # Save the image in JPG format\n",
    "        image.save(aoi_image_file_path, \"JPEG\")\n",
    "        print(f\"AOI image saved at {aoi_image_file_path}\")\n",
    "    else:\n",
    "        print(\"No image to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google maps view extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# GoogleMapDownloader.py \n",
    "# Created by Adrien de Jaur√©guiberry\n",
    "#\n",
    "# A script which when given a longitude, latitude, length\n",
    "# returns a high resolution google map\n",
    "\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "import os\n",
    "from math import *\n",
    "\n",
    "class GoogleMapDownloader:\n",
    "    \"\"\"\n",
    "        A class which generates high resolution google maps images given\n",
    "        a gmap API key and location parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, API_key, lat, lng, lgth, img_size=1000):\n",
    "        \"\"\"\n",
    "            GoogleMapDownloader Constructor\n",
    "            Args:\n",
    "                API_key:  The GoogleMap API key to load images\n",
    "                lat:      The latitude of the location required\n",
    "                lng:      The longitude of the location required\n",
    "                lgth:     Length of the map in m. The map will be a square.\n",
    "                          warning: too big length will result in distorded map due to mercator projection.\n",
    "                img_size: The resolution of the output image as img_size X img_size\n",
    "                          default to 1000\n",
    "        \"\"\"\n",
    "        lat_rad = (pi/180)*lat\n",
    "        self._img_size = img_size\n",
    "        self._lat = lat\n",
    "        self._lng = lng\n",
    "        self._zoom = floor(log2(156543.03 * img_size / lgth))\n",
    "        self._resolution = 156543.03 / (2 ** self._zoom) #(m/px)\n",
    "        self._nb_tiles = ceil(img_size/500)\n",
    "        self._tile_lgth = lgth/self._nb_tiles\n",
    "        self._tile_size = int(self._tile_lgth/self._resolution)\n",
    "        self._API_key = API_key\n",
    "\n",
    "    def getMercatorFromGPS(self,lng,lat):\n",
    "    \tx = 6371000 * lng\n",
    "    \ty = 6371000 * log(tan(pi/4 + lat/2))\n",
    "    \treturn (x,y)\n",
    "\n",
    "    def getGPSFromMercator(self,x,y):\n",
    "    \tlng = x/6371000\n",
    "    \tlat = 2*atan(exp(y/6371000)) - pi/2\n",
    "    \treturn (lng,lat)\n",
    "    \n",
    "    def get_zoom_level(self):\n",
    "        return self._zoom\n",
    "\n",
    "    def generateImage(self):\n",
    "        \"\"\"\n",
    "            Generates an image by stitching a number of google map tiles together.\n",
    "            \n",
    "            Returns:\n",
    "                A high-resolution Goole Map image.\n",
    "        \"\"\"\n",
    "\n",
    "        lat_rad = (pi/180)*abs(self._lat)\n",
    "        lng_rad = (pi/180)*abs(self._lng)\n",
    "        xy_loc  = self.getMercatorFromGPS(lng_rad,lat_rad)\n",
    "\n",
    "        xy_with_step  = [xy_loc[0]+self._tile_lgth , xy_loc[1]+self._tile_lgth]\n",
    "        gps_with_step = self.getGPSFromMercator(xy_with_step[0], xy_with_step[1])\n",
    "\n",
    "        lat_step = (180/pi)*(gps_with_step[1] - lat_rad)\n",
    "        lon_step = (180/pi)*(gps_with_step[0] - lng_rad)\n",
    "\n",
    "        border = 20        \n",
    "\n",
    "        # Determine the size of the image\n",
    "        width, height = self._tile_size * self._nb_tiles, self._tile_size * self._nb_tiles\n",
    "\n",
    "        #Create a new image of the size require\n",
    "        map_img = Image.new('RGB', (width,height))\n",
    "\n",
    "\n",
    "        nb_tiles_max = self._nb_tiles**2\n",
    "        counter = 1\n",
    "        print(f\"Generating AOI image...\")\n",
    "        with tqdm(total=nb_tiles_max, desc=\"Downloading tiles\", unit=\"tile\") as pbar:\n",
    "\n",
    "            for x in range(0, self._nb_tiles):\n",
    "                for y in range(0, self._nb_tiles) :\n",
    "\n",
    "                    la = self._lat - y*lat_step + lat_step*(self._nb_tiles-1)/2\n",
    "                    lo = self._lng + x*lon_step - lon_step*(self._nb_tiles-1)/2\n",
    "\n",
    "                    url = 'https://maps.googleapis.com/maps/api/staticmap?'\n",
    "                    url += 'center='+str(la)+','+str(lo)\n",
    "                    url += '&zoom='+str(self._zoom)\n",
    "                    url += '&size='+str(self._tile_size+2*border)+'x'+str(self._tile_size+2*border)\n",
    "                    url += '&maptype=satellite'\n",
    "                    if self._API_key:url += '&key='+self._API_key\n",
    "    #                 print('getting tile '+str(counter)+\"/\"+str(nb_tiles_max))\n",
    "                    counter+=1\n",
    "\n",
    "                    current_tile = str(x)+'-'+str(y)\n",
    "                    request.urlretrieve(url, current_tile)\n",
    "\n",
    "                    im = Image.open(current_tile)\n",
    "                    map_img.paste(im.crop((border,border,self._tile_size+border,self._tile_size+border)), (x*self._tile_size, y*self._tile_size))\n",
    "\n",
    "                    os.remove(current_tile)\n",
    "                    # Update the progress bar\n",
    "                    pbar.update(1)\n",
    "\n",
    "        print(\"Resizing map\")\n",
    "        return map_img.resize((self._img_size,self._img_size))\n",
    "\n",
    "import os\n",
    "\n",
    "def download_map_image(api_key, lat, lng, map_length, image_size):\n",
    "    gmd = GoogleMapDownloader(api_key, lat, lng, map_length, image_size)\n",
    "    try:\n",
    "        # Generate the high-resolution map image\n",
    "        return gmd.generateImage()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not generate the image - {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get the zoom level\n",
    "def get_map_zoom(api_key, lat, lng, map_length, image_size):\n",
    "    gmd = GoogleMapDownloader(api_key, lat, lng, map_length, image_size)\n",
    "    return gmd.get_zoom_level()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get image dimensions\n",
    "def get_image_dimensions(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found or the path is incorrect\")\n",
    "    return image.shape[1], image.shape[0]  # Width, Height\n",
    "\n",
    "def kernal_window_finder(image_width_px, image_height_px, covered_area_width_km, covered_area_height_km, target_area_width_km, target_area_height_km):\n",
    "    \"\"\"\n",
    "    Calculate the pixel dimensions for a given kilometer area in an image, rounded to the nearest whole number.\n",
    "\n",
    "    Parameters:\n",
    "    image_width_px (int): Width of the image in pixels.\n",
    "    image_height_px (int): Height of the image in pixels.\n",
    "    covered_area_width_km (float): Width of the area covered by the image in kilometers.\n",
    "    covered_area_height_km (float): Height of the area covered by the image in kilometers.\n",
    "    target_area_width_km (float): Width of the target area in kilometers.\n",
    "    target_area_height_km (float): Height of the target area in kilometers.\n",
    "\n",
    "    Returns:\n",
    "    (int, int): Width and height of the target area in pixels, rounded to the nearest whole number.\n",
    "    \"\"\"\n",
    "\n",
    "    # The number of pixels per km in both dimensions\n",
    "    pixels_per_km_width = image_width_px / covered_area_width_km\n",
    "    pixels_per_km_height = image_height_px / covered_area_height_km\n",
    "\n",
    "    # Calculating the pixel dimensions for the target area\n",
    "    target_area_width_px = round(target_area_width_km * pixels_per_km_width)\n",
    "    target_area_height_px = round(target_area_height_km * pixels_per_km_height)\n",
    "\n",
    "    return target_area_width_px, target_area_height_px\n",
    "\n",
    "def determine_multipliers(area_km2):\n",
    "    \"\"\"\n",
    "    Determine the multipliers for window size and stride based on the area in square kilometers.\n",
    "\n",
    "    Parameters:\n",
    "    area_km2 (float): The area in square kilometers.\n",
    "\n",
    "    Returns:\n",
    "    (float, float, float): Multipliers for window width, window height, and stride.\n",
    "    \"\"\"\n",
    "    if area_km2 < 2500:\n",
    "        return 1.6, 1\n",
    "    elif 2500 <= area_km2 <= 8100:\n",
    "        return 1.25, 0.5\n",
    "    else:  # area_km2 > 8100\n",
    "        return 1, 0.2\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def subsample_images(image_path, output_folder, window_width, window_height, stride_x, stride_y):\n",
    "    \"\"\"\n",
    "    Generate subsampled images from a reference image using a sliding window and print the total number of images generated.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): Path to the reference image.\n",
    "    output_folder (str): Path to the folder where subsampled images will be saved.\n",
    "    window_width (int): Width of the sliding window in pixels.\n",
    "    window_height (int): Height of the sliding window in pixels.\n",
    "    stride_x (int): Horizontal stride of the sliding window in pixels.\n",
    "    stride_y (int): Vertical stride of the sliding window in pixels.\n",
    "    \"\"\"\n",
    "    # Load the reference image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Calculate the total number of subsamples to be generated for the progress bar\n",
    "    total_subsamples = ((image.width - window_width) // stride_x + 1) * ((image.height - window_height) // stride_y + 1)\n",
    "\n",
    "    print(\"Generating subsampled images...\")\n",
    "\n",
    "    with tqdm(total=total_subsamples, desc=\"Subsampling\", unit=\"image\") as pbar:\n",
    "        # Iterate over the image using the sliding window\n",
    "        for y in range(0, image.height - window_height + 1, stride_y):\n",
    "            for x in range(0, image.width - window_width + 1, stride_x):\n",
    "                # Extract the sub-image\n",
    "                sub_image = image.crop((x, y, x + window_width, y + window_height))\n",
    "\n",
    "                # Save the sub-image\n",
    "                sub_image_path = os.path.join(output_folder, f\"subsample_{x}_{y}.jpg\")\n",
    "                sub_image.save(sub_image_path)\n",
    "                \n",
    "                # Update the progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "    print(\"Completed subsampling.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resize_image(image, max_size=800):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = max_size / max(h, w)\n",
    "\n",
    "    if scale < 1:\n",
    "        image = cv2.resize(image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)\n",
    "    return image\n",
    "\n",
    "def sift_detect_and_compute(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return None, None\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def match_features(descriptors1, descriptors2):\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return []\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    # Ensure there are at least 2 matches to unpack\n",
    "    if len(matches) < 2:\n",
    "        return []\n",
    "    return matches\n",
    "\n",
    "\n",
    "def filter_good_matches(matches):\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "def find_homography(keypoints1, keypoints2, good_matches):\n",
    "    if not good_matches:\n",
    "        return None, None\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return M, mask\n",
    "def is_mostly_blue(image, water_ratio_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Check if an image is predominantly water by analyzing the color histogram and contours.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): Image to check for water (blue) color.\n",
    "    water_ratio_threshold (float): The ratio of water to the total area of the image.\n",
    "\n",
    "    Returns:\n",
    "    bool, float: Whether the image is mostly water, and the ratio of water in the image.\n",
    "    \"\"\"\n",
    "    # Convert the image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # Define the range for blue color in HSV\n",
    "    lower_blue = np.array([100, 50, 50])\n",
    "    upper_blue = np.array([140, 255, 255])\n",
    "    # Create a mask for blue color\n",
    "    blue_mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "    # Calculate the ratio of blue pixels\n",
    "    water_pixels = np.sum(blue_mask) / 255\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    water_ratio = water_pixels / total_pixels\n",
    "\n",
    "    # Determine if the image is mostly blue based on the water ratio\n",
    "    is_mostly_blue = water_ratio > water_ratio_threshold\n",
    "#     print(\"is_mostly_blue_value water_ratio:\", water_ratio)\n",
    "    return is_mostly_blue\n",
    "\n",
    "def visualize_matches(image1, keypoints1, image2, keypoints2, matches, mask):\n",
    "    if mask is None:\n",
    "        print(\"Homography could not be computed.\")\n",
    "        return\n",
    "    draw_params = dict(matchColor=(0, 255, 0),\n",
    "                       singlePointColor=None,\n",
    "                       matchesMask=mask.ravel().tolist(),\n",
    "                       flags=2)\n",
    "    img_matches = cv2.drawMatches(image1, keypoints1, image2, keypoints2, matches, None, **draw_params)\n",
    "    img_matches = cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(img_matches)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def match_query_to_scene(query_image_path, scene_image_path):\n",
    "    query_image = cv2.imread(query_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if query_image is None:\n",
    "        raise ValueError(f\"Could not load the query image from path: {query_image_path}\")\n",
    "    query_image = resize_image(query_image)\n",
    "\n",
    "    scene_image = cv2.imread(scene_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if scene_image is None:\n",
    "        raise ValueError(f\"Could not load the scene image from path: {scene_image_path}\")\n",
    "    scene_image = resize_image(scene_image)\n",
    "\n",
    "    keypoints_query, descriptors_query = sift_detect_and_compute(query_image)\n",
    "    keypoints_scene, descriptors_scene = sift_detect_and_compute(scene_image)\n",
    "\n",
    "    matches = match_features(descriptors_query, descriptors_scene)\n",
    "    good_matches = filter_good_matches(matches)\n",
    "\n",
    "    if len(good_matches) > 10:\n",
    "        M, mask = find_homography(keypoints_query, keypoints_scene, good_matches)\n",
    "        if M is not None:\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "            matching_percentage = (sum(matchesMask) / len(good_matches)) * 100\n",
    "            message = f\"Match found with {scene_image_path}: {matching_percentage:.2f}%   \"\n",
    "            print(message.ljust(100), end='\\r')\n",
    "            return scene_image_path, matching_percentage, (keypoints_scene, good_matches, matchesMask)\n",
    "    else:\n",
    "        pass\n",
    "#         print(f\"Not enough good matches found for {scene_image_path}\")\n",
    "\n",
    "    return scene_image_path, 0, (None, None, None)  # Return zero if homography not found or not enough good matches\n",
    "\n",
    "# def calculate_center_pixel(keypoints_scene, good_matches, matchesMask):\n",
    "#     matched_pts = [keypoints_scene[m.trainIdx].pt for m, mask in zip(good_matches, matchesMask) if mask]\n",
    "#     if not matched_pts:\n",
    "#         return (0, 0)\n",
    "#     x, y = zip(*matched_pts)\n",
    "#     center_x, center_y = sum(x) / len(x), sum(y) / len(y)\n",
    "#     return int(center_x), int(center_y)\n",
    "\n",
    "# def pixel_to_geo(pixel_x, pixel_y, top_left_geo, bottom_right_geo, image_width_px, image_height_px):\n",
    "#     lat_range = bottom_right_geo[0] - top_left_geo[0]\n",
    "#     lon_range = bottom_right_geo[1] - top_left_geo[1]\n",
    "\n",
    "#     geo_x = top_left_geo[1] + (pixel_x / image_width_px) * lon_range\n",
    "#     geo_y = top_left_geo[0] + (pixel_y / image_height_px) * lat_range\n",
    "\n",
    "#     return geo_x, geo_y\n",
    "\n",
    "def calculate_pixel_to_geo(top_left_geo, bottom_right_geo, image_width_px, image_height_px, pixel_x, pixel_y):\n",
    "    # New function to calculate geographic coordinates from pixel coordinates\n",
    "    lat_range = bottom_right_geo[0] - top_left_geo[0]\n",
    "    lon_range = bottom_right_geo[1] - top_left_geo[1]\n",
    "\n",
    "    lat_per_pixel = lat_range / image_height_px\n",
    "    lon_per_pixel = lon_range / image_width_px\n",
    "\n",
    "    geo_x = top_left_geo[1] + pixel_x * lon_per_pixel\n",
    "    geo_y = top_left_geo[0] + pixel_y * lat_per_pixel\n",
    "\n",
    "    return geo_y, geo_x\n",
    "\n",
    "def compare_images_with_query(query_image_path, directory_path, num_matches=1):\n",
    "    best_match_paths = []\n",
    "\n",
    "    matches_info = []\n",
    "#     start_time = time.time()\n",
    "\n",
    "    for image_path in glob.glob(directory_path + '/*.jpg'):\n",
    "        try:\n",
    "            # Load the scene image in color to check for blue\n",
    "            scene_image_color = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            if scene_image_color is None:\n",
    "                raise ValueError(f\"Could not load the scene image from path: {image_path}\")\n",
    "\n",
    "            # Check if the image is mostly blue\n",
    "            if is_mostly_blue(scene_image_color):\n",
    "                message = f\"Skipping predominantly blue image: {image_path}   \"\n",
    "                print(message.ljust(100), end='\\r')\n",
    "                continue  # Skip this image\n",
    "                \n",
    "            image_path, matching_percentage, match_data = match_query_to_scene(query_image_path, image_path)\n",
    "            matches_info.append((image_path, matching_percentage, match_data))\n",
    "        except Exception as e:\n",
    "            print(f\"Error comparing images: {e}\")\n",
    "\n",
    "    matches_info.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get top N matches based on num_matches\n",
    "    for i in range(min(num_matches, len(matches_info))):\n",
    "        best_match_info = matches_info[i]\n",
    "        best_match_path, best_match_percentage, _ = best_match_info\n",
    "        print(f\"Visualizing match with {best_match_path}: {best_match_percentage:.2f}%\")\n",
    "        match_query_to_scene(query_image_path, best_match_path)\n",
    "        best_match_paths.append(best_match_path)\n",
    "\n",
    "#     total_time = time.time() - start_time\n",
    "#     print(f\"Total time taken: {total_time:.2f} seconds\")\n",
    "\n",
    "    return best_match_paths\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_subsample_offsets(best_match_path):\n",
    "    # Extract the file name without the directory\n",
    "    file_name = os.path.basename(best_match_path)\n",
    "    # Split the file name into parts\n",
    "    parts = file_name.split('_')\n",
    "    # The offsets are the last two parts before the file extension, convert them to integers\n",
    "    offset_x = int(parts[-2])\n",
    "    offset_y = int(parts[-1].split('.')[0])  # Remove the file extension before converting\n",
    "    return offset_x, offset_y\n",
    "\n",
    "def get_center_pixel_of_subsample(subsample_path):\n",
    "    subsample_image = cv2.imread(subsample_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if subsample_image is None:\n",
    "        raise ValueError(f\"Could not load the subsample image from path: {subsample_path}\")\n",
    "    h, w = subsample_image.shape[:2]\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "    return center_x, center_y\n",
    "\n",
    "def calculate_subsample_geo_center(subsample_path, large_area_image_path, top_left_geo, bottom_right_geo, subsample_offset_x, subsample_offset_y):\n",
    "    # Get the dimensions of the large area image\n",
    "    large_image_width_px, large_image_height_px = get_image_dimensions(large_area_image_path)\n",
    "\n",
    "    # Calculate the center pixel of the subsample\n",
    "    center_pixel_x, center_pixel_y = get_center_pixel_of_subsample(subsample_path)\n",
    "\n",
    "    # Calculate the absolute pixel coordinates of the center in the large area image\n",
    "    absolute_center_x = subsample_offset_x + center_pixel_x\n",
    "    absolute_center_y = subsample_offset_y + center_pixel_y\n",
    "\n",
    "    # Convert these absolute pixel coordinates to geographic coordinates\n",
    "    geo_center = calculate_pixel_to_geo(top_left_geo, bottom_right_geo, large_image_width_px, large_image_height_px, absolute_center_x, absolute_center_y)\n",
    "    \n",
    "    return geo_center\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate distance between two sets of coordinates\n",
    "def calculate_distance(coord1, coord2):\n",
    "    return geodesic(coord1, coord2).kilometers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_iss_image(query_image_name, api_key):\n",
    "    # Loading query image and extracting metadata \n",
    "\n",
    "    query_image_folder = \"../data/images/\"\n",
    "    query_image_name = query_image_name   \n",
    "    query_image_path = query_image_folder + query_image_name    \n",
    "\n",
    "    exif_data = get_exif_data(query_image_path)\n",
    "\n",
    "#     print(f\"Extracted Metadata:\\n {exif_data}\")\n",
    "\n",
    "\n",
    "    gps_latitude = exif_data.get('GPSLatitude', None)\n",
    "    gps_latitude_ref = exif_data.get('GPSLatitudeRef', None)\n",
    "    gps_longitude = exif_data.get('GPSLongitude', None)\n",
    "    gps_longitude_ref = exif_data.get('GPSLongitudeRef', None)\n",
    "    gps_altitude = exif_data.get('GPSAltitude', None)\n",
    "    focal_length = exif_data.get('FocalLength', None)\n",
    "\n",
    "    # Check if all GPS data is available\n",
    "    if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n",
    "        lat, long = get_geo_coord(gps_latitude, gps_latitude_ref, gps_longitude, gps_longitude_ref)\n",
    "        print(f\"ISS coordinates: {lat}, {long}\")\n",
    "    else:\n",
    "        print(\"GPS data is incomplete or not available in the image.\")\n",
    "\n",
    "\n",
    "    # These correspond to a Nikon D5\n",
    "    sensor_width = 36  # in millimeters (for a full-frame sensor like Nikon D5)\n",
    "    sensor_height = 24  # in millimeters\n",
    "\n",
    "    # Distance of the ISS camera to earth\n",
    "    distance = gps_altitude /1000  # in kilometers\n",
    "\n",
    "    # scene dimensions in kilometers. It will help in finding the kernal size of sliding window.\n",
    "    fov_horizontal, fov_vertical, query_image_width_km, query_image_height_km = calculate_fov_and_scene_dimensions(focal_length, sensor_width, sensor_height, distance)\n",
    "    print(f\"scene width: {query_image_width_km} km and scene height: {query_image_height_km} km\")\n",
    "\n",
    "\n",
    "    # Downloading area of interest image and getting bounding box coordinates\n",
    "    api_key = api_key\n",
    "    map_length = 1200000  # in meters\n",
    "    image_size = 30000  # width and height in pixels\n",
    "    aoi_image_folder = \"../data/aoi_images/\"\n",
    "\n",
    "    # AOI image file path construction\n",
    "    aoi_image_base_name = os.path.splitext(query_image_name)[0] + \"_aoi.jpg\"\n",
    "    aoi_image_file_path = os.path.join(aoi_image_folder, aoi_image_base_name)\n",
    "\n",
    "    # Instantiate GoogleMapDownloader object\n",
    "    gmd = GoogleMapDownloader(api_key, lat, long, map_length, image_size)\n",
    "\n",
    "    # Check if AOI image already exists\n",
    "    if not os.path.exists(aoi_image_file_path):\n",
    "        # Download the map image if it doesn't exist\n",
    "        image = gmd.generateImage()\n",
    "\n",
    "        # Save the image if it is not None\n",
    "        if image is not None:\n",
    "            # Ensure the folder exists\n",
    "            os.makedirs(aoi_image_folder, exist_ok=True)\n",
    "\n",
    "            # Save the image in JPG format\n",
    "            image.save(aoi_image_file_path, \"JPEG\")\n",
    "            print(f\"AOI image saved at {aoi_image_file_path}\")\n",
    "        else:\n",
    "            print(\"No image to save.\")\n",
    "    else:\n",
    "        print(f\"AOI image already exists at {aoi_image_file_path}\")\n",
    "\n",
    "    # Retrieve the zoom level in both cases (new download or existing file)\n",
    "    zoom = gmd.get_zoom_level()\n",
    "#     print(f\"Zoom level: {zoom}\")\n",
    "\n",
    "\n",
    "    # # manual check inputs:\n",
    "    # aoi_image_file_path =\"../data/aoi_images/iss050e070478_aoi.jpg\"\n",
    "    # zoom =11\n",
    "\n",
    "\n",
    "    # Calculate the bounding box coordinates\n",
    "    top_left_aoi, top_right_aoi, bottom_right_aoi, bottom_left_aoi = calculate_mapbox_bounding_box(lat, long, zoom, image_size, image_size)\n",
    "#     print(\"top_left_aoi:\",top_left_aoi)\n",
    "#     print(\"top_right_aoi:\",top_right_aoi)\n",
    "#     print(\"bottom_right_aoi:\",bottom_right_aoi)\n",
    "#     print(\"bottom_left_aoi:\",bottom_left_aoi)\n",
    "\n",
    "\n",
    "    # Using SIFT matcher\n",
    "    distance_km = map_length/2000  # convert meters in kilometers\n",
    "    rounded_width_km = math.ceil(query_image_width_km)\n",
    "    rounded_height_km = math.ceil(query_image_height_km)\n",
    "    kernal_width_px, kernal_height_px = kernal_window_finder(image_size, image_size, distance_km, distance_km, rounded_width_km, rounded_height_km)\n",
    "#     print(\"Kernal Width in pixels:\", kernal_width_px, \", Kernal Height in pixels:\", kernal_height_px)\n",
    "\n",
    "    area_km2 = rounded_width_km * rounded_height_km\n",
    "    window_multiplier, stride_multiplier = determine_multipliers(area_km2)\n",
    "\n",
    "    window_width = math.ceil(kernal_width_px * window_multiplier)\n",
    "    window_height = math.ceil(kernal_height_px * window_multiplier)\n",
    "    stride_x = math.ceil(kernal_width_px * stride_multiplier)\n",
    "    stride_y = math.ceil(kernal_height_px * stride_multiplier)\n",
    "\n",
    "#     # best for images with area covered: 8km x 12km \n",
    "#     window_width = math.ceil(kernal_width_px*1.6)\n",
    "#     window_height = math.ceil(kernal_height_px*1.6)\n",
    "#     stride_x = math.ceil(kernal_width_px)\n",
    "#     stride_y = math.ceil(kernal_height_px)\n",
    "\n",
    "    # best for images with area covered: 59km x 89km\n",
    "#     window_width = math.ceil(kernal_width_px*1.25)\n",
    "#     window_height = math.ceil(kernal_height_px*1.25)\n",
    "#     stride_x = math.ceil(kernal_width_px/2)\n",
    "#     stride_y = math.ceil(kernal_height_px/2) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Extract the base name without extension\n",
    "    base_name = os.path.splitext(query_image_name)[0]\n",
    "    # Create output folder path\n",
    "    aoi_subsample_output_folder_base = \"../data/aoi_subsampled_images/\"\n",
    "    aoi_subsample_output_folder_path = os.path.join(aoi_subsample_output_folder_base, \"subsampled_\" + base_name)\n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(aoi_subsample_output_folder_path):\n",
    "        os.makedirs(aoi_subsample_output_folder_path)\n",
    "#         # Call the function \n",
    "#         subsample_images(aoi_image_file_path, aoi_subsample_output_folder_path, window_width, window_height, stride_x, stride_y)\n",
    "#     else: \n",
    "#         print(f\"Sampled images already exists at: {aoi_subsample_output_folder_path}\")\n",
    "\n",
    "    # Call the function \n",
    "    subsample_images(aoi_image_file_path, aoi_subsample_output_folder_path, window_width, window_height, stride_x, stride_y)\n",
    " \n",
    "    \n",
    "    # Run the comparison and get top N matches\n",
    "    num_matches = 2  # Set the number of matches you want\n",
    "    best_match_paths = compare_images_with_query(query_image_path, aoi_subsample_output_folder_path, num_matches)\n",
    "    large_area_image_path = aoi_image_file_path \n",
    "    top_left_geo = top_left_aoi\n",
    "    bottom_right_geo = bottom_right_aoi\n",
    "\n",
    "    # Initialize a list to store geographic centers\n",
    "    geo_centers = []\n",
    "\n",
    "    # Process each match in the list\n",
    "    for match_path in best_match_paths:\n",
    "        # Extract the subsample offsets\n",
    "        subsample_offset_x, subsample_offset_y = extract_subsample_offsets(match_path)\n",
    "\n",
    "        # Calculate the geographic center coordinates\n",
    "        geo_center = calculate_subsample_geo_center(match_path, large_area_image_path, top_left_geo, bottom_right_geo, subsample_offset_x, subsample_offset_y)\n",
    "        print(f\"Geographic center of {match_path}: {geo_center}\")\n",
    "\n",
    "        # Append the geographic center to the list\n",
    "        geo_centers.append(geo_center)\n",
    "    \n",
    "    return geo_centers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing the result excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openpyxl import load_workbook\n",
    "# import os\n",
    "\n",
    "# # Replace with the path to your Excel file\n",
    "# excel_file_path = '../results/results_SIFT.xlsx'\n",
    "# api_key = \"AIzaSyDz3J0WrbihXKVxJ50R1Aa1ZWwL5TGmq5E\"\n",
    "\n",
    "# # Load the workbook and select the active worksheet\n",
    "# wb = load_workbook(excel_file_path)\n",
    "# ws = wb.active\n",
    "\n",
    "# # Iterate through the rows in the worksheet\n",
    "# for row in ws.iter_rows(min_row=2, max_col=5):\n",
    "#     image_cell, location_from_code_cell = row[0], row[4]\n",
    "\n",
    "#     # If 'Location from code' is empty and 'Image' is not empty\n",
    "#     if not location_from_code_cell.value and image_cell.value:\n",
    "#         print(f\"Processing image: {image_cell.value}\")\n",
    "#         query_image_name = image_cell.value + \".jpg\"\n",
    "\n",
    "#         # Call your function to get the geographic centers\n",
    "#         geo_centers = process_iss_image(query_image_name, api_key)\n",
    "\n",
    "#         # Update the cell with the list of geo centers\n",
    "#         location_from_code_cell.value = ', '.join(f\"({lat}, {lon})\" for lat, lon in geo_centers)\n",
    "\n",
    "# # Save the workbook\n",
    "# wb.save(excel_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: iss065e053870\n",
      "ISS coordinates: 39.51998, 25.729667729930885\n",
      "scene width: 37.91531454545454 km and scene height: 25.27687636363636 km\n",
      "Generating AOI image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tiles:   0%|          | 12/3600 [00:02<10:50,  5.51tile/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-721b3187fd74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Call your function to get the geographic centers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mgeo_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_iss_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_image_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure this function is defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Update the DataFrame with the geo centers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b575e588acfa>\u001b[0m in \u001b[0;36mprocess_iss_image\u001b[0;34m(query_image_name, api_key)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maoi_image_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Download the map image if it doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Save the image if it is not None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2cb648f0fba7>\u001b[0m in \u001b[0;36mgenerateImage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mcurrent_tile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_tile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_tile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# Function to calculate distance between two sets of coordinates\n",
    "# (Assuming 'calculate_distance' function is defined elsewhere in your code)\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_file_path = '../results/results_SIFT_v2_csv.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Existing code\n",
    "api_key = getpass.getpass(\"Enter your api key: \")\n",
    "\n",
    "# Clear the console\n",
    "clear_output(wait=True)\n",
    "    \n",
    "    \n",
    "# Iterate through the DataFrame's rows\n",
    "for index, row in df.iterrows():\n",
    "    image_name = row['Image']\n",
    "    labeled_location = row['Location']\n",
    "    pred_loc1 = row['Predicted Location 1']\n",
    "    pred_loc2 = row['Predicted Location 2']\n",
    "    dist1 = row['Distance Labeled to Predicted 1']\n",
    "    dist2 = row['Distance Labeled to Predicted 2']\n",
    "\n",
    "    # Check if the 'Image' is not empty and other specified columns are empty\n",
    "    if not pd.isna(image_name) and pd.isna(pred_loc1) and pd.isna(pred_loc2) and pd.isna(dist1) and pd.isna(dist2):\n",
    "        start_time = time.time()  # Start the timer\n",
    "        print(f\"Processing image: {image_name}\")\n",
    "        query_image_name = image_name + \".jpg\"\n",
    "\n",
    "        # Call your function to get the geographic centers\n",
    "        geo_centers = process_iss_image(query_image_name, api_key)  # Ensure this function is defined\n",
    "\n",
    "        # Update the DataFrame with the geo centers\n",
    "        df.at[index, 'Predicted Location 1'] = f\"{geo_centers[0][0]}, {geo_centers[0][1]}\"\n",
    "        df.at[index, 'Predicted Location 2'] = f\"{geo_centers[1][0]}, {geo_centers[1][1]}\"\n",
    "\n",
    "        # Only calculate distances if 'Location' is not empty\n",
    "        if not pd.isna(labeled_location):\n",
    "            labeled_lat, labeled_lon = map(float, labeled_location.split(', '))\n",
    "            dist_to_pred1 = calculate_distance((labeled_lat, labeled_lon), geo_centers[0])\n",
    "            dist_to_pred2 = calculate_distance((labeled_lat, labeled_lon), geo_centers[1])\n",
    "            df.at[index, 'Distance Labeled to Predicted 1'] = dist_to_pred1\n",
    "            df.at[index, 'Distance Labeled to Predicted 2'] = dist_to_pred2\n",
    "        else:\n",
    "            df.at[index, 'Distance Labeled to Predicted 1'] = None\n",
    "            df.at[index, 'Distance Labeled to Predicted 2'] = None\n",
    "\n",
    "        # Save the updated DataFrame back to a CSV file after processing each row\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        end_time = time.time()  # Stop the timer\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Completed processing {image_name}. Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "print(\"All images processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > SIFT_matcher_requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMA915f0wWqoCTWRdp9vlsI",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
